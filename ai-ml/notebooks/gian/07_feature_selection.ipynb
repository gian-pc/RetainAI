{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ” Notebook 07: Feature Selection\n",
    "\n",
    "**Autor:** Gian  \n",
    "**Fecha:** 2026-01-19  \n",
    "**Objetivo:** Seleccionar las caracterÃ­sticas mÃ¡s relevantes para alimentar el modelo de Machine Learning, reduciendo la dimensionalidad y el ruido.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ Contenido\n",
    "\n",
    "1. ConfiguraciÃ³n del entorno\n",
    "2. Carga de datos (Dataset Enriquecido)\n",
    "3. Filtrado por CorrelaciÃ³n (Multicolinealidad)\n",
    "4. SelecciÃ³n por Mutual Information\n",
    "5. SelecciÃ³n por Recursive Feature Elimination (RFE)\n",
    "6. Importancia de CaracterÃ­sticas (Random Forest)\n",
    "7. ConsolidaciÃ³n y SelecciÃ³n Final\n",
    "8. Guardado del Dataset Reducido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. ConfiguraciÃ³n del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T22:07:23.268890Z",
     "start_time": "2026-01-19T22:07:23.256728Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.feature_selection import mutual_info_classif, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… LibrerÃ­as importadas correctamente\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LibrerÃ­as importadas correctamente\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Carga de Datos\n",
    "Cargamos `06_data_engineered.csv` del paso anterior."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T22:07:23.398706Z",
     "start_time": "2026-01-19T22:07:23.282361Z"
    }
   },
   "source": [
    "# Rutas\n",
    "OUTPUT_PATH = Path(\"../../outputs/gian\")\n",
    "DATA_PATH = OUTPUT_PATH / \"data\" / \"06_data_engineered.csv\"\n",
    "SELECTED_DATA_PATH = OUTPUT_PATH / \"data\"\n",
    "REPORTS_PATH = OUTPUT_PATH / \"reports\"\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"âœ… Dataset cargado: {df.shape[0]:,} registros Ã— {df.shape[1]} columnas\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset cargado: 9,701 registros Ã— 104 columnas\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Filtrado por CorrelaciÃ³n (Multicolinealidad)\n",
    "Eliminamos variables que estÃ©n altamente correlacionadas entre sÃ­ (rho > 0.9), manteniendo la que tenga mayor correlaciÃ³n con el target (si es posible) o simplemente la primera."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T22:07:23.547189Z",
     "start_time": "2026-01-19T22:07:23.417442Z"
    }
   },
   "source": [
    "# Matriz de correlaciÃ³n\n",
    "corr_matrix = df.corr(numeric_only=True).abs()\n",
    "\n",
    "# Seleccionar triangulo superior\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Identificar columnas con correlaciÃ³n > 0.90\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.90)]\n",
    "\n",
    "print(f\"âš ï¸ Columnas a eliminar por alta correlaciÃ³n ({len(to_drop)}):\")\n",
    "print(to_drop[:10]) # Mostrar primeras 10\n",
    "\n",
    "df_filtered = df.drop(columns=to_drop)\n",
    "print(f\"\\nðŸ“Š Shape despuÃ©s de eliminar correlacionadas: {df_filtered.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Columnas a eliminar por alta correlaciÃ³n (15):\n",
      "['tasa_clics_marketing', 'riesgo_soporte_interaccion', 'valor_diario_cliente', 'log_errores_pago', 'log_tickets_soporte', 'log_antiguedad', 'borough_MANHATTAN', 'lineas_multiples_Sin servicio', 'seguridad_online_No internet service', 'respaldo_online_No internet service']\n",
      "\n",
      "ðŸ“Š Shape despuÃ©s de eliminar correlacionadas: (9701, 89)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. SelecciÃ³n por Mutual Information\n",
    "Calculamos la ganancia de informaciÃ³n entre cada feature y el target (`cancelacion`)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T22:07:24.183099Z",
     "start_time": "2026-01-19T22:07:23.551846Z"
    }
   },
   "source": [
    "X = df_filtered.select_dtypes(include=['number']).drop(columns=['cancelacion', 'cliente_id'], errors='ignore')\n",
    "y = df_filtered['cancelacion']\n",
    "\n",
    "# Calcular Mutual Information \n",
    "# (Usamos una muestra si el dataset fuera gigante, pero con 9k registros estÃ¡ bien usar todo)\n",
    "mi_scores = mutual_info_classif(X, y, random_state=42)\n",
    "mi_scores = pd.Series(mi_scores, name=\"MI_Score\", index=X.columns)\n",
    "mi_scores = mi_scores.sort_values(ascending=False)\n",
    "\n",
    "print(\"ðŸ† Top 10 Features por Mutual Information:\")\n",
    "print(mi_scores.head(10))\n",
    "\n",
    "# Seleccionamos Top 30 (Arbitrario, para comparar)\n",
    "top_mi_features = mi_scores.head(30).index.tolist()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ† Top 10 Features por Mutual Information:\n",
      "score_riesgo              0.265987\n",
      "dias_activos_semanales    0.265851\n",
      "promedio_conexion         0.264081\n",
      "conexiones_mensuales      0.263101\n",
      "caracteristicas_usadas    0.261464\n",
      "dias_ultima_conexion      0.245053\n",
      "intensidad_uso            0.223572\n",
      "tickets_soporte           0.192153\n",
      "puntuacion_nps            0.174049\n",
      "tasa_crecimiento_uso      0.148301\n",
      "Name: MI_Score, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. SelecciÃ³n por Recursive Feature Elimination (RFE)\n",
    "Usamos Random Forest como estimador base para ir eliminando recursivamente las features menos importantes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T22:07:26.880908Z",
     "start_time": "2026-01-19T22:07:24.186692Z"
    }
   },
   "source": [
    "# Usamos un modelo 'ligero' para RFE\n",
    "model_rfe = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Seleccionar 20 mejores\n",
    "rfe = RFE(model_rfe, n_features_to_select=20)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "top_rfe_features = X.columns[rfe.support_].tolist()\n",
    "\n",
    "print(\"ðŸ† Features seleccionadas por RFE:\")\n",
    "print(top_rfe_features)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ† Features seleccionadas por RFE:\n",
      "['latitud', 'longitud', 'codigo_postal', 'antiguedad', 'cargo_mensual', 'ingresos_totales', 'errores_pago', 'score_riesgo', 'conexiones_mensuales', 'dias_activos_semanales', 'promedio_conexion', 'caracteristicas_usadas', 'tasa_crecimiento_uso', 'dias_ultima_conexion', 'tickets_soporte', 'tiempo_resolucion', 'puntuacion_csat', 'intensidad_uso', 'dias_desde_ultimo_contacto', 'ratio_carga_financiera']\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Importancia de CaracterÃ­sticas (Random Forest Completo)\n",
    "Entrenamos un modelo robusto y extraemos `feature_importances_`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T22:07:27.418820Z",
     "start_time": "2026-01-19T22:07:26.932696Z"
    }
   },
   "source": [
    "rf_full = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_full.fit(X, y)\n",
    "\n",
    "importances = pd.Series(rf_full.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "\n",
    "print(\"ðŸ† Top 10 Features por Random Forest Importance:\")\n",
    "print(importances.head(10))\n",
    "\n",
    "top_rf_features = importances.head(25).index.tolist()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ† Top 10 Features por Random Forest Importance:\n",
      "conexiones_mensuales      0.146455\n",
      "promedio_conexion         0.117092\n",
      "caracteristicas_usadas    0.116998\n",
      "dias_activos_semanales    0.090268\n",
      "score_riesgo              0.084496\n",
      "dias_ultima_conexion      0.062194\n",
      "tickets_soporte           0.043844\n",
      "tasa_crecimiento_uso      0.034518\n",
      "puntuacion_csat           0.027942\n",
      "puntuacion_nps            0.025263\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. ConsolidaciÃ³n y SelecciÃ³n Final\n",
    "Hacemos una votaciÃ³n: features que aparezcan en al menos 2 de los 3 mÃ©todos (MI, RFE, RF)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T22:07:27.434432Z",
     "start_time": "2026-01-19T22:07:27.431793Z"
    }
   },
   "source": [
    "# Unimos todas las listas\n",
    "all_selected = top_mi_features + top_rfe_features + top_rf_features\n",
    "\n",
    "# Contamos frecuencia\n",
    "from collections import Counter\n",
    "counts = Counter(all_selected)\n",
    "\n",
    "# Seleccionamos las que aparecen al menos en 2 mÃ©todos\n",
    "final_features = [feat for feat, count in counts.items() if count >= 2]\n",
    "\n",
    "# Asegurarnos de incluir el target y IDs si es necesario para el tracking\n",
    "final_columns = ['cliente_id', 'cancelacion'] + final_features\n",
    "\n",
    "print(f\"âœ… NÃºmero final de features seleccionadas (sin ID/Target): {len(final_features)}\")\n",
    "print(\"ðŸ“‹ Lista Final:\", final_features)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… NÃºmero final de features seleccionadas (sin ID/Target): 24\n",
      "ðŸ“‹ Lista Final: ['score_riesgo', 'dias_activos_semanales', 'promedio_conexion', 'conexiones_mensuales', 'caracteristicas_usadas', 'dias_ultima_conexion', 'intensidad_uso', 'tickets_soporte', 'puntuacion_nps', 'tasa_crecimiento_uso', 'puntuacion_csat', 'ratio_carga_financiera', 'tasa_apertura_email', 'errores_pago', 'antiguedad', 'ingresos_totales', 'latitud', 'cargo_mensual', 'tiempo_resolucion', 'longitud', 'codigo_postal', 'edad', 'dias_desde_ultimo_contacto', 'tiempo_sesion_promedio']\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Guardado del Dataset Reducido"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T22:07:27.612600Z",
     "start_time": "2026-01-19T22:07:27.438485Z"
    }
   },
   "source": [
    "# Filtrar dataset\n",
    "df_final = df[final_columns].copy()\n",
    "\n",
    "# Guardar\n",
    "output_file = SELECTED_DATA_PATH / \"07_data_selected.csv\"\n",
    "df_final.to_csv(output_file, index=False)\n",
    "\n",
    "# Guardar reporte\n",
    "pd.DataFrame(final_features, columns=['Feature']).to_csv(REPORTS_PATH / \"07_selected_features_list.csv\", index=False)\n",
    "\n",
    "print(f\"ðŸ’¾ Dataset reducido guardado en: {output_file}\")\n",
    "print(f\"ðŸ“Š Nuevas dimensiones: {df_final.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¾ Dataset reducido guardado en: ../../outputs/gian/data/07_data_selected.csv\n",
      "ðŸ“Š Nuevas dimensiones: (9701, 26)\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
