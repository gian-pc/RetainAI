# üìä Gu√≠a del Dataset Original Limpio - RetainAI

## üéØ Prop√≥sito

Este documento explica el **dataset original limpio** que debe usar el equipo para an√°lisis y desarrollo, **sin contaminaci√≥n** de features calculados por pipelines de ML.

---

## üìÅ Ubicaci√≥n del Dataset

**Archivo:** [`data/clean/original_dataset_clean.csv`](file:///Users/admin/Desktop/projects/hackathon-oracle/RetainAI/ai-ml/data/clean/original_dataset_clean.csv)

- **Registros:** 10,000 clientes
- **Columnas:** 32 (todas originales)
- **Tama√±o:** 1.75 MB
- **Encoding:** UTF-8

---

## ‚ö†Ô∏è ¬øPor qu√© este dataset?

### El Problema

El dataset `retain-data.csv` estaba **contaminado** con 43 columnas de feature engineering calculadas autom√°ticamente por notebooks y pipelines de ML:

- ‚ùå `retain-data.csv`: **77 columnas** (32 originales + 45 calculadas)
- ‚úÖ `original_dataset_clean.csv`: **32 columnas** (solo originales)

### Columnas Contaminadas Eliminadas

Se eliminaron columnas como:
- `tenure_group`, `income_bracket`, `nps_categoria` (features derivados)
- `ServicioTelefono_Binary`, `LineasMultiples_Binary` (features binarios)
- `Log_ChargesMonthly`, `Sqrt_Tenure` (transformaciones matem√°ticas)
- `HighRisk_ContractTenure`, `IncomePriceMismatch` (features de interacci√≥n)

---

## üìã Columnas del Dataset (32)

### 1. Identificaci√≥n
- `cliente_id` - ID √∫nico del cliente

### 2. Informaci√≥n Demogr√°fica
- `genero` - G√©nero del cliente (Masculino/Femenino)
- `edad` - Edad del cliente
- `pais` - Pa√≠s de residencia
- `ciudad` - Ciudad de residencia

### 3. Segmentaci√≥n
- `segmento_de_cliente` - Segmento (Individual/SME/Enterprise)
- `meses_permanencia` - Meses como cliente
- `canal_de_registro` - Canal de registro (Web/Mobile/Tienda)

### 4. Contrato y Servicios
- `tipo_contrato` - Tipo de contrato (Mensual/Anual/Bianual)
- `conecciones_mensuales` - N√∫mero de conexiones mensuales
- `dias_activos_semanales` - D√≠as activos por semana
- `promedio_coneccion` - Promedio de tiempo de conexi√≥n
- `caracteristicas_usadas` - N√∫mero de caracter√≠sticas usadas
- `tasa_crecimiento_uso` - Tasa de crecimiento de uso
- `ultima_coneccion` - D√≠as desde √∫ltima conexi√≥n

### 5. Facturaci√≥n
- `cuota_mensual` - Cuota mensual en USD
- `ingresos_totales` - Ingresos totales generados
- `metodo_de_pago` - M√©todo de pago (PayPal/Tarjeta/Transferencia)
- `errores_de_pago` - N√∫mero de errores de pago
- `descuento_aplicado` - Si tiene descuento aplicado (Si/No)
- `aumento_ultimos_3_meses` - Si hubo aumento en √∫ltimos 3 meses (Si/No)

### 6. Soporte y Satisfacci√≥n
- `tickets_de_soporte` - N√∫mero de tickets de soporte
- `tiempo_promedio_de_resolucion` - Tiempo promedio de resoluci√≥n (horas)
- `tipo_de_queja` - Tipo de queja principal
- `puntuacion_csates` - Puntuaci√≥n CSAT (1-5)
- `escaladas` - N√∫mero de escaladas

### 7. Marketing y Engagement
- `tasa_apertura_email` - Tasa de apertura de emails (0-1)
- `tasa_clics_marketing` - Tasa de clics en marketing (0-1)
- `puntuacion_nps` - Puntuaci√≥n NPS (-100 a 100)
- `respuesta_de_la_encuesta` - Respuesta de encuesta (Satisfecho/Neutral/Insatisfecho)
- `recuento_de_referencias` - N√∫mero de referencias hechas

### 8. Variable Objetivo
- `abandonar` - Si el cliente abandon√≥ (0=No, 1=S√≠) **‚Üê TARGET VARIABLE**

---

## üîÑ C√≥mo se Reconstruy√≥

El dataset se reconstruy√≥ usando el script [`scripts/rebuild_clean_dataset.py`](file:///Users/admin/Desktop/projects/hackathon-oracle/RetainAI/ai-ml/scripts/rebuild_clean_dataset.py):

```bash
python3 scripts/rebuild_clean_dataset.py
```

### Archivos Fuente Originales

1. **`data/original/alura_telecomx_original.json`**
   - Datos de telecomunicaciones en formato JSON
   
2. **`data/original/Archived_Legally_Operating_Businesses_20240924.csv`**
   - Datos demogr√°ficos y geogr√°ficos de NYC (281K registros)
   
3. **`data/raw/customer_dataset.csv`**
   - Dataset principal de clientes (10K registros, 32 columnas)

> **Nota:** El archivo `customer_dataset.csv` ya contiene la uni√≥n de los 3 archivos fuente, por lo que es el dataset base limpio.

---

## üíª C√≥mo Usar el Dataset

### Cargar en Python

```python
import pandas as pd

# Cargar dataset limpio
df = pd.read_csv('data/clean/original_dataset_clean.csv')

print(f"Registros: {len(df):,}")
print(f"Columnas: {len(df.columns)}")
print(f"\nPrimeras filas:")
print(df.head())

# Verificar variable objetivo
print(f"\nDistribuci√≥n de Churn:")
print(df['abandonar'].value_counts())
```

### An√°lisis Exploratorio

```python
# Informaci√≥n general
df.info()

# Estad√≠sticas descriptivas
df.describe()

# Valores nulos
print(df.isnull().sum())

# Distribuci√≥n de segmentos
print(df['segmento_de_cliente'].value_counts())
```

### Feature Engineering (cuando sea necesario)

Si necesitas crear features calculados para ML, hazlo **din√°micamente** en tu c√≥digo, NO los guardes en el CSV:

```python
# ‚úÖ CORRECTO: Calcular features en memoria
def create_features(df):
    df = df.copy()
    
    # Crear features derivados
    df['tenure_group'] = pd.cut(df['meses_permanencia'], 
                                 bins=[0, 12, 24, 48, 100],
                                 labels=['0-12', '13-24', '25-48', '49+'])
    
    df['ratio_precio_ingreso'] = df['cuota_mensual'] * 12 / df['ingresos_totales']
    
    return df

# Usar en entrenamiento
df_train = create_features(df)
```

```python
# ‚ùå INCORRECTO: Guardar features calculados en CSV
df['tenure_group'] = ...
df.to_csv('dataset_with_features.csv')  # NO HACER ESTO
```

---

## üö´ Datasets a NO Usar

Estos datasets est√°n contaminados con features calculados:

- ‚ùå `data/processed/retain-data.csv` (77 columnas - CONTAMINADO)
- ‚ùå `data/processed/01_dataset_clean.csv` (puede tener features calculados)
- ‚ùå Cualquier CSV con m√°s de 32 columnas

---

## ‚úÖ Validaci√≥n del Dataset

Para verificar que el dataset est√° limpio:

```python
import pandas as pd

df = pd.read_csv('data/clean/original_dataset_clean.csv')

# Verificar n√∫mero de columnas
assert len(df.columns) == 32, "Dataset contaminado: m√°s de 32 columnas"

# Verificar que no haya columnas calculadas
calculated_patterns = ['_Binary', 'Log_', 'Sqrt_', 'tenure_group', 'income_bracket']
for col in df.columns:
    for pattern in calculated_patterns:
        assert pattern not in col, f"Columna calculada encontrada: {col}"

print("‚úÖ Dataset limpio validado correctamente")
```

---

## üîÑ Re-generar el Dataset

Si necesitas re-generar el dataset limpio:

```bash
cd ai-ml
python3 scripts/rebuild_clean_dataset.py
```

Esto crear√° un nuevo `data/clean/original_dataset_clean.csv` desde los archivos fuente.

---

## üìû Soporte

Si tienes dudas sobre el dataset:

1. Revisa este documento
2. Verifica que est√°s usando `data/clean/original_dataset_clean.csv`
3. Confirma que el dataset tiene exactamente 32 columnas
4. Consulta con el equipo de ML si necesitas crear features calculados

---

**√öltima actualizaci√≥n:** 2026-01-18  
**Versi√≥n del dataset:** 1.0  
**Registros:** 10,000 clientes  
**Columnas:** 32 (todas originales)
