{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4c8e5a",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [5]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1436a248",
   "metadata": {
    "papermill": {
     "duration": 0.004418,
     "end_time": "2026-01-16T15:11:39.184599",
     "exception": false,
     "start_time": "2026-01-16T15:11:39.180181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DS-506: Evaluaci√≥n Exhaustiva del Modelo Campe√≥n en TEST\n",
    "\n",
    "**Objetivo**: Evaluar el modelo campe√≥n (Logistic Regression) en el conjunto de TEST para validar que est√° listo para producci√≥n\n",
    "\n",
    "**Input**: \n",
    "- `data/processed/retain-data.csv`\n",
    "- `models/champion/logistic_regression.pkl`\n",
    "- `models/champion/scaler.pkl`\n",
    "- `models/champion/label_encoder.pkl`\n",
    "\n",
    "**Output**: \n",
    "- M√©tricas finales en TEST\n",
    "- Matriz de confusi√≥n detallada\n",
    "- An√°lisis de errores (falsos positivos/negativos)\n",
    "- An√°lisis de threshold √≥ptimo\n",
    "- Coeficientes del modelo (feature importance)\n",
    "- Reporte final ejecutivo\n",
    "\n",
    "---\n",
    "\n",
    "## üìã ¬øPor qu√© TEST es cr√≠tico?\n",
    "\n",
    "En DS-505 entrenamos y optimizamos hiperpar√°metros usando **Train** y **Validation**. El conjunto de **TEST** NUNCA fue visto durante el entrenamiento.\n",
    "\n",
    "**TEST nos dice la verdad:**\n",
    "- ¬øEl modelo realmente generaliza?\n",
    "- ¬øLas m√©tricas de validaci√≥n eran realistas o hubo overfitting?\n",
    "- ¬øEst√° listo para producci√≥n?\n",
    "\n",
    "Si TEST tiene m√©tricas similares a Validation (diferencia <5%), el modelo es **robusto** y podemos desplegarlo con confianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57daa47a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.108856Z",
     "start_time": "2026-01-11T03:53:37.927399Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-16T15:11:39.193759Z",
     "iopub.status.busy": "2026-01-16T15:11:39.193396Z",
     "iopub.status.idle": "2026-01-16T15:11:40.466404Z",
     "shell.execute_reply": "2026-01-16T15:11:40.466084Z"
    },
    "papermill": {
     "duration": 1.278991,
     "end_time": "2026-01-16T15:11:40.467197",
     "exception": false,
     "start_time": "2026-01-16T15:11:39.188206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Librer√≠as importadas\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix,\n",
    "    classification_report, ConfusionMatrixDisplay,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "# Configuraci√≥n\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Semilla (DEBE ser la misma que DS-505 para obtener el MISMO split)\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"‚úì Librer√≠as importadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67870cee",
   "metadata": {
    "papermill": {
     "duration": 0.002839,
     "end_time": "2026-01-16T15:11:40.473246",
     "exception": false,
     "start_time": "2026-01-16T15:11:40.470407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Carga de Datos y Recreaci√≥n del Split\n",
    "\n",
    "### üéØ ¬øPor qu√© recrear el split?\n",
    "\n",
    "Necesitamos el **MISMO conjunto de TEST** que usamos en DS-505. Al usar `random_state=42`, scikit-learn garantiza que el split es id√©ntico.\n",
    "\n",
    "### üìä Divisi√≥n:\n",
    "- Train: 70% (4,929 clientes)\n",
    "- Validation: 15% (1,057 clientes)\n",
    "- **TEST: 15% (1,057 clientes)** ‚Üê Este es el que evaluaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "221dd693",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.158554Z",
     "start_time": "2026-01-11T03:53:38.121232Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-16T15:11:40.480282Z",
     "iopub.status.busy": "2026-01-16T15:11:40.480090Z",
     "iopub.status.idle": "2026-01-16T15:11:40.543782Z",
     "shell.execute_reply": "2026-01-16T15:11:40.543446Z"
    },
    "papermill": {
     "duration": 0.068109,
     "end_time": "2026-01-16T15:11:40.544615",
     "exception": false,
     "start_time": "2026-01-16T15:11:40.476506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset cargado: 9,701 clientes √ó 77 columnas\n",
      "üìã Features para ML: 62 variables\n",
      "\n",
      "‚úì X: (9701, 62)\n",
      "‚úì y: (9701,)\n"
     ]
    }
   ],
   "source": [
    "# Cargar dataset\n",
    "df = pd.read_csv('../data/processed/retain-data.csv')\n",
    "\n",
    "# Cargar metadata de features\n",
    "with open('../data/processed/04_features_metadata.json', 'r') as f:\n",
    "    features_meta = json.load(f)\n",
    "\n",
    "ml_features = features_meta['ml_features']\n",
    "\n",
    "print(f\"üìä Dataset cargado: {df.shape[0]:,} clientes √ó {df.shape[1]} columnas\")\n",
    "print(f\"üìã Features para ML: {len(ml_features)} variables\")\n",
    "\n",
    "# Separar X y y\n",
    "X = df[ml_features].copy()\n",
    "y = df['Cancelacion'].copy()\n",
    "\n",
    "print(f\"\\n‚úì X: {X.shape}\")\n",
    "print(f\"‚úì y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a19961e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.181315Z",
     "start_time": "2026-01-11T03:53:38.162834Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-16T15:11:40.551251Z",
     "iopub.status.busy": "2026-01-16T15:11:40.551122Z",
     "iopub.status.idle": "2026-01-16T15:11:40.575884Z",
     "shell.execute_reply": "2026-01-16T15:11:40.575511Z"
    },
    "papermill": {
     "duration": 0.029302,
     "end_time": "2026-01-16T15:11:40.577092",
     "exception": false,
     "start_time": "2026-01-16T15:11:40.547790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì One-Hot Encoding completado: 62 ‚Üí 162 features\n"
     ]
    }
   ],
   "source": [
    "# Encoding de categ√≥ricas (igual que en DS-505)\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True, dtype=int)\n",
    "\n",
    "print(f\"‚úì One-Hot Encoding completado: {X.shape[1]} ‚Üí {X_encoded.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13f90bfe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.208857Z",
     "start_time": "2026-01-11T03:53:38.196130Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-16T15:11:40.585051Z",
     "iopub.status.busy": "2026-01-16T15:11:40.584882Z",
     "iopub.status.idle": "2026-01-16T15:11:40.605627Z",
     "shell.execute_reply": "2026-01-16T15:11:40.605181Z"
    },
    "papermill": {
     "duration": 0.025411,
     "end_time": "2026-01-16T15:11:40.606617",
     "exception": false,
     "start_time": "2026-01-16T15:11:40.581206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Divisi√≥n de datos recreada:\n",
      "\n",
      "   Train:      6,789 clientes (70%)\n",
      "   Validation: 1,456 clientes (15%)\n",
      "   TEST:       1,456 clientes (15%) ‚Üê EVALUAREMOS AQU√ç\n",
      "\n",
      "‚úì Distribuci√≥n de churn en TEST: 16.00%\n"
     ]
    }
   ],
   "source": [
    "# Recrear el MISMO split de DS-505\n",
    "# Primera divisi√≥n: Train+Val (85%) vs Test (15%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X_encoded, y, \n",
    "    test_size=0.15, \n",
    "    stratify=y, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Segunda divisi√≥n: Train (70%) vs Validation (15%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=0.1765,  # 15% del total\n",
    "    stratify=y_temp, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"üìä Divisi√≥n de datos recreada:\\n\")\n",
    "print(f\"   Train:      {X_train.shape[0]:,} clientes (70%)\")\n",
    "print(f\"   Validation: {X_val.shape[0]:,} clientes (15%)\")\n",
    "print(f\"   TEST:       {X_test.shape[0]:,} clientes (15%) ‚Üê EVALUAREMOS AQU√ç\")\n",
    "\n",
    "print(f\"\\n‚úì Distribuci√≥n de churn en TEST: {(y_test == 'Si').sum() / len(y_test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23685963",
   "metadata": {
    "papermill": {
     "duration": 0.003493,
     "end_time": "2026-01-16T15:11:40.614186",
     "exception": false,
     "start_time": "2026-01-16T15:11:40.610693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Carga del Modelo Campe√≥n\n",
    "\n",
    "### üéØ ¬øQu√© cargamos?\n",
    "\n",
    "El modelo **Logistic Regression** que fue seleccionado como campe√≥n en DS-505 por su mejor AUC (0.9088) y menor overfitting (0.3%).\n",
    "\n",
    "### üì¶ Artifacts necesarios:\n",
    "1. **logistic_regression.pkl**: El modelo entrenado\n",
    "2. **scaler.pkl**: StandardScaler para normalizar features\n",
    "3. **label_encoder.pkl**: Para codificar el target (Yes/No ‚Üí 1/0)\n",
    "4. **metadata.json**: Informaci√≥n del modelo (hiperpar√°metros, m√©tricas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32352005",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0131dfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.294993Z",
     "start_time": "2026-01-11T03:53:38.213514Z"
    },
    "execution": {
     "iopub.execute_input": "2026-01-16T15:11:40.621811Z",
     "iopub.status.busy": "2026-01-16T15:11:40.621576Z",
     "iopub.status.idle": "2026-01-16T15:11:40.965121Z",
     "shell.execute_reply": "2026-01-16T15:11:40.964535Z"
    },
    "papermill": {
     "duration": 0.348455,
     "end_time": "2026-01-16T15:11:40.965946",
     "exception": true,
     "start_time": "2026-01-16T15:11:40.617491",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/champion/logistic_regression.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Cargar modelo campe√≥n y artifacts\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_champion \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../models/champion/logistic_regression.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m scaler \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/champion/scaler.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../models/champion/label_encoder.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/numpy_pickle.py:735\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    733\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj, ensure_native_byte_order\u001b[38;5;241m=\u001b[39mensure_native_byte_order)\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 735\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[1;32m    737\u001b[0m             fobj,\n\u001b[1;32m    738\u001b[0m             validated_mmap_mode,\n\u001b[1;32m    739\u001b[0m         ):\n\u001b[1;32m    740\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    741\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    742\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    743\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/champion/logistic_regression.pkl'"
     ]
    }
   ],
   "source": [
    "# Cargar modelo campe√≥n y artifacts\n",
    "model_champion = joblib.load('../models/champion/logistic_regression.pkl')\n",
    "scaler = joblib.load('../models/champion/scaler.pkl')\n",
    "label_encoder = joblib.load('../models/champion/label_encoder.pkl')\n",
    "\n",
    "# Cargar metadata\n",
    "with open('../models/champion/metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(\"‚úÖ Modelo Campe√≥n Cargado:\\n\")\n",
    "print(f\"   ‚Ä¢ Tipo: {metadata.get('model_name', 'Unknown')}\")\n",
    "print(f\"   ‚Ä¢ Fecha entrenamiento: {metadata['training_date']}\")\n",
    "print(f\"   ‚Ä¢ Hiperpar√°metros: C={metadata['hyperparameters']['C']}, solver={metadata['hyperparameters']['solver']}\")\n",
    "print(f\"\\nüìä M√©tricas en Validation (DS-505):\")\n",
    "print(f\"   ‚Ä¢ AUC: {metadata['performance_metrics']['auc_val']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Precision: {metadata['performance_metrics']['precision_val']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall: {metadata['performance_metrics']['recall_val']:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {metadata['performance_metrics']['f1_val']:.4f}\")\n",
    "print(f\"\\nüí° Objetivo: Validar que m√©tricas en TEST sean similares (diferencia <5%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bc1176",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 3. Preparaci√≥n del Conjunto de TEST\n",
    "\n",
    "### üéØ ¬øQu√© hacemos?\n",
    "\n",
    "Aplicamos las **mismas transformaciones** que se usaron en Train/Validation:\n",
    "1. Escalar features num√©ricas con el **mismo scaler** (ajustado solo con Train)\n",
    "2. Codificar el target con el **mismo label_encoder**\n",
    "\n",
    "### ‚ö†Ô∏è Importante:\n",
    "**NO ajustamos** (fit) nada con TEST. Solo **transformamos** (transform) usando los par√°metros aprendidos de Train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f2005",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.317657Z",
     "start_time": "2026-01-11T03:53:38.309162Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Codificar target de TEST\n",
    "y_test_encoded = label_encoder.transform(y_test)  # Yes ‚Üí 1, No ‚Üí 0\n",
    "\n",
    "# Identificar features num√©ricas\n",
    "numeric_features = X_test.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Escalar TEST con el scaler ajustado en Train\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "\n",
    "print(\"‚úì TEST preparado:\")\n",
    "print(f\"   ‚Ä¢ Features escaladas: {len(numeric_features)}\")\n",
    "print(f\"   ‚Ä¢ Target codificado: Yes={label_encoder.transform(['Si'])[0]}, No={label_encoder.transform(['No'])[0]}\")\n",
    "print(f\"   ‚Ä¢ Clientes en TEST: {len(X_test_scaled):,}\")\n",
    "print(f\"   ‚Ä¢ Churners en TEST: {y_test_encoded.sum():,} ({y_test_encoded.sum() / len(y_test_encoded) * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d688b4f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4. Predicciones en TEST\n",
    "\n",
    "### üéØ ¬øQu√© obtenemos?\n",
    "\n",
    "El modelo genera **dos tipos** de predicciones:\n",
    "\n",
    "1. **Clase predicha** (0 o 1): Decisi√≥n binaria usando threshold 0.5\n",
    "   - Si probabilidad ‚â• 0.5 ‚Üí Predice churn (1)\n",
    "   - Si probabilidad < 0.5 ‚Üí Predice no churn (0)\n",
    "\n",
    "2. **Probabilidad** (0.0 - 1.0): Confianza del modelo\n",
    "   - 0.95 = 95% seguro que va a cancelar\n",
    "   - 0.20 = 20% probabilidad de cancelar\n",
    "\n",
    "### üí° ¬øPor qu√© necesitamos ambas?\n",
    "- **Clase**: Para calcular m√©tricas (Precision, Recall, F1)\n",
    "- **Probabilidad**: Para AUC y para ajustar threshold de negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb1b60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.335079Z",
     "start_time": "2026-01-11T03:53:38.328494Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predicciones en TEST\n",
    "y_test_pred = model_champion.predict(X_test_scaled)\n",
    "y_test_proba = model_champion.predict_proba(X_test_scaled)[:, 1]  # Probabilidad de clase 1 (churn)\n",
    "\n",
    "print(\"‚úÖ Predicciones en TEST generadas:\\n\")\n",
    "print(f\"   ‚Ä¢ Total predicciones: {len(y_test_pred):,}\")\n",
    "print(f\"   ‚Ä¢ Predichos como churn: {y_test_pred.sum():,} ({y_test_pred.sum() / len(y_test_pred) * 100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Predichos como no churn: {(1 - y_test_pred).sum():,} ({(1 - y_test_pred).sum() / len(y_test_pred) * 100:.1f}%)\")\n",
    "print(f\"\\nüìä Distribuci√≥n de probabilidades:\")\n",
    "print(f\"   ‚Ä¢ M√≠nima: {y_test_proba.min():.4f}\")\n",
    "print(f\"   ‚Ä¢ M√°xima: {y_test_proba.max():.4f}\")\n",
    "print(f\"   ‚Ä¢ Media: {y_test_proba.mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Mediana: {np.median(y_test_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73bdcf",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5. M√©tricas Finales en TEST\n",
    "\n",
    "### üéØ ¬øQu√© vemos aqu√≠?\n",
    "\n",
    "Las **m√©tricas definitivas** del modelo en datos nunca vistos.\n",
    "\n",
    "### üìä C√≥mo interpretar cada m√©trica:\n",
    "\n",
    "**AUC-ROC (0.5 - 1.0)**:\n",
    "- Capacidad global del modelo para discriminar entre churn/no-churn\n",
    "- >0.90 = Excelente, >0.80 = Muy bueno, >0.70 = Bueno\n",
    "\n",
    "**Accuracy**:\n",
    "- % de predicciones correctas (churn + no churn)\n",
    "- ‚ö†Ô∏è M√©trica enga√±osa si hay desbalanceo (tenemos 73.5% no churn)\n",
    "\n",
    "**Precision**:\n",
    "- De los que **predecimos** como churn, ¬øcu√°ntos **realmente** lo son?\n",
    "- Alta precision = Evitamos molestar clientes que no van a cancelar\n",
    "\n",
    "**Recall (Sensibilidad)**:\n",
    "- De los que **realmente** cancelan, ¬øcu√°ntos **detectamos**?\n",
    "- Alto recall = No perdemos churners reales\n",
    "- **M√©trica m√°s cr√≠tica** para retenci√≥n de clientes\n",
    "\n",
    "**F1-Score**:\n",
    "- Media arm√≥nica de Precision y Recall\n",
    "- Balance entre ambas m√©tricas\n",
    "\n",
    "### üí° Comparaci√≥n con Validation:\n",
    "Si TEST ‚âà Validation (diferencia <5%), el modelo **generaliza bien** y est√° listo para producci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95007db3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.353950Z",
     "start_time": "2026-01-11T03:53:38.344801Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcular m√©tricas en TEST\n",
    "auc_test = roc_auc_score(y_test_encoded, y_test_proba)\n",
    "accuracy_test = accuracy_score(y_test_encoded, y_test_pred)\n",
    "precision_test = precision_score(y_test_encoded, y_test_pred)\n",
    "recall_test = recall_score(y_test_encoded, y_test_pred)\n",
    "f1_test = f1_score(y_test_encoded, y_test_pred)\n",
    "\n",
    "# Cargar m√©tricas de Validation (de metadata)\n",
    "auc_val = metadata['performance_metrics']['auc_val']\n",
    "precision_val = metadata['performance_metrics']['precision_val']\n",
    "recall_val = metadata['performance_metrics']['recall_val']\n",
    "f1_val = metadata['performance_metrics']['f1_val']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä M√âTRICAS FINALES - CONJUNTO DE TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüéØ VALIDATION (DS-505):\")\n",
    "print(f\"   ‚Ä¢ AUC:       {auc_val:.4f}\")\n",
    "print(f\"   ‚Ä¢ Accuracy:  {metadata['performance_metrics'].get('accuracy_val', 'N/A')}\")\n",
    "print(f\"   ‚Ä¢ Precision: {precision_val:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall:    {recall_val:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {f1_val:.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ TEST (EVALUACI√ìN FINAL):\")\n",
    "print(f\"   ‚Ä¢ AUC:       {auc_test:.4f}\")\n",
    "print(f\"   ‚Ä¢ Accuracy:  {accuracy_test:.4f}\")\n",
    "print(f\"   ‚Ä¢ Precision: {precision_test:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall:    {recall_test:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {f1_test:.4f}\")\n",
    "\n",
    "# Calcular diferencias\n",
    "diff_auc = abs(auc_test - auc_val) / auc_val * 100\n",
    "diff_precision = abs(precision_test - precision_val) / precision_val * 100\n",
    "diff_recall = abs(recall_test - recall_val) / recall_val * 100\n",
    "diff_f1 = abs(f1_test - f1_val) / f1_val * 100\n",
    "\n",
    "print(f\"\\nüìà DIFERENCIA TEST vs VALIDATION:\")\n",
    "print(f\"   ‚Ä¢ AUC:       {diff_auc:+.2f}%\")\n",
    "print(f\"   ‚Ä¢ Precision: {diff_precision:+.2f}%\")\n",
    "print(f\"   ‚Ä¢ Recall:    {diff_recall:+.2f}%\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {diff_f1:+.2f}%\")\n",
    "\n",
    "# Diagn√≥stico\n",
    "if diff_auc < 5 and diff_f1 < 5:\n",
    "    print(f\"\\n‚úÖ DIAGN√ìSTICO: Modelo GENERALIZA EXCELENTE (diferencia <5%)\")\n",
    "    print(f\"   El modelo est√° LISTO para producci√≥n.\")\n",
    "elif diff_auc < 10 and diff_f1 < 10:\n",
    "    print(f\"\\n‚ö†Ô∏è DIAGN√ìSTICO: Modelo generaliza bien (diferencia <10%)\")\n",
    "    print(f\"   El modelo es aceptable para producci√≥n, pero monitorear de cerca.\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå DIAGN√ìSTICO: Posible overfitting (diferencia >10%)\")\n",
    "    print(f\"   Considerar reentrenar con m√°s regularizaci√≥n.\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2484b863",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 6. Matriz de Confusi√≥n\n",
    "\n",
    "### üéØ ¬øQu√© es la matriz de confusi√≥n?\n",
    "\n",
    "Tabla que muestra los **4 posibles resultados** de la predicci√≥n:\n",
    "\n",
    "```\n",
    "                    Predicci√≥n\n",
    "                No Churn  |  Churn\n",
    "Real  No Churn     TN     |   FP     (Falso Positivo: Predecimos churn pero NO cancela)\n",
    "      Churn        FN     |   TP     (Falso Negativo: Predecimos no churn pero S√ç cancela)\n",
    "```\n",
    "\n",
    "### üìä Interpretaci√≥n:\n",
    "\n",
    "**True Negatives (TN)**: ‚úÖ Correctos\n",
    "- Predecimos que NO van a cancelar ‚Üí Y efectivamente NO cancelan\n",
    "\n",
    "**True Positives (TP)**: ‚úÖ Correctos\n",
    "- Predecimos que S√ç van a cancelar ‚Üí Y efectivamente cancelan\n",
    "\n",
    "**False Positives (FP)**: ‚ùå Error Tipo I\n",
    "- Predecimos churn pero NO cancelan\n",
    "- **Costo**: Malgastamos recursos de retenci√≥n en clientes que no se iban a ir\n",
    "\n",
    "**False Negatives (FN)**: ‚ùå Error Tipo II\n",
    "- Predecimos que NO van a cancelar pero S√ç cancelan\n",
    "- **Costo**: Perdemos el cliente (NO M√ÅS CR√çTICO)\n",
    "\n",
    "### üí° ¬øQu√© buscamos?\n",
    "- **TP alto**: Detectar la mayor√≠a de churners\n",
    "- **FN bajo**: No perder churners reales\n",
    "- Balance entre FP y FN seg√∫n el costo de negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048b58d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.376461Z",
     "start_time": "2026-01-11T03:53:38.369953Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcular matriz de confusi√≥n\n",
    "cm = confusion_matrix(y_test_encoded, y_test_pred)\n",
    "\n",
    "# Extraer valores\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"üìä MATRIZ DE CONFUSI√ìN - TEST\\n\")\n",
    "print(f\"                 Predicci√≥n\")\n",
    "print(f\"              No Churn  |  Churn\")\n",
    "print(f\"Real  No      {tn:>6}    |  {fp:>6}    (Falso Positivo)\")\n",
    "print(f\"      Churn   {fn:>6}    |  {tp:>6}    (Falso Negativo)\\n\")\n",
    "\n",
    "# Interpretaci√≥n\n",
    "total = tn + fp + fn + tp\n",
    "print(f\"‚úÖ True Negatives (TN): {tn:,} ({tn/total*100:.1f}%)\")\n",
    "print(f\"   ‚Üí Predecimos NO churn y efectivamente NO cancelan\\n\")\n",
    "\n",
    "print(f\"‚úÖ True Positives (TP): {tp:,} ({tp/total*100:.1f}%)\")\n",
    "print(f\"   ‚Üí Predecimos churn y efectivamente cancelan\\n\")\n",
    "\n",
    "print(f\"‚ùå False Positives (FP): {fp:,} ({fp/total*100:.1f}%)\")\n",
    "print(f\"   ‚Üí Predecimos churn pero NO cancelan\")\n",
    "print(f\"   ‚Üí Costo: Malgastamos recursos de retenci√≥n\\n\")\n",
    "\n",
    "print(f\"‚ùå False Negatives (FN): {fn:,} ({fn/total*100:.1f}%)\")\n",
    "print(f\"   ‚Üí Predecimos NO churn pero S√ç cancelan\")\n",
    "print(f\"   ‚Üí Costo: PERDEMOS EL CLIENTE (m√°s grave)\\n\")\n",
    "\n",
    "# C√°lculo de tasas\n",
    "print(f\"üìà TASAS DERIVADAS:\\n\")\n",
    "print(f\"   ‚Ä¢ Tasa de Falsos Positivos (FPR): {fp/(fp+tn)*100:.2f}%\")\n",
    "print(f\"     De los que NO cancelan, cu√°ntos predecimos mal como churn\\n\")\n",
    "\n",
    "print(f\"   ‚Ä¢ Tasa de Falsos Negativos (FNR): {fn/(fn+tp)*100:.2f}%\")\n",
    "print(f\"     De los que S√ç cancelan, cu√°ntos perdemos por no detectar\\n\")\n",
    "\n",
    "print(f\"   ‚Ä¢ Recall (TPR): {tp/(tp+fn)*100:.2f}%\")\n",
    "print(f\"     De los que S√ç cancelan, cu√°ntos detectamos correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2509afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.647326Z",
     "start_time": "2026-01-11T03:53:38.380721Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizar matriz de confusi√≥n\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "disp = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm,\n",
    "    display_labels=['No Churn', 'Cancelacion']\n",
    ")\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='d')\n",
    "\n",
    "plt.title('Matriz de Confusi√≥n - TEST', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('Predicci√≥n', fontsize=12)\n",
    "plt.ylabel('Realidad', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/06_confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Visualizaci√≥n guardada: reports/figures/06_confusion_matrix.png\")\n",
    "\n",
    "# Guardar matriz en CSV\n",
    "cm_df = pd.DataFrame(\n",
    "    cm,\n",
    "    index=['Real: No Churn', 'Real: Churn'],\n",
    "    columns=['Pred: No Churn', 'Pred: Churn']\n",
    ")\n",
    "cm_df.to_csv('../reports/06_confusion_matrix.csv')\n",
    "print(\"‚úì Matriz guardada: reports/06_confusion_matrix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff932b2a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 7. Curva ROC en TEST\n",
    "\n",
    "### üéØ ¬øQu√© es la curva ROC?\n",
    "\n",
    "Gr√°fico que muestra el **trade-off** entre:\n",
    "- **TPR (True Positive Rate = Recall)**: De los churners reales, cu√°ntos detectamos\n",
    "- **FPR (False Positive Rate)**: De los no churners, cu√°ntos predecimos mal como churn\n",
    "\n",
    "### üìä Interpretaci√≥n:\n",
    "\n",
    "- **L√≠nea diagonal (AUC=0.5)**: Modelo aleatorio (lanzar moneda)\n",
    "- **Curva cerca de esquina superior izquierda**: Modelo excelente\n",
    "  - Alto TPR (detectamos muchos churners)\n",
    "  - Bajo FPR (pocos falsos positivos)\n",
    "- **AUC (√Årea bajo la curva)**: Resumen num√©rico\n",
    "  - 1.0 = Perfecto\n",
    "  - 0.9 = Excelente\n",
    "  - 0.8 = Muy bueno\n",
    "  - 0.7 = Bueno\n",
    "  - 0.5 = Aleatorio\n",
    "\n",
    "### üí° ¬øQu√© buscamos?\n",
    "Que el AUC en TEST sea **similar al de Validation** (diferencia <5%). Esto confirma que el modelo generaliza y no hay overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339ec33b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.934613Z",
     "start_time": "2026-01-11T03:53:38.657773Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcular curva ROC en TEST\n",
    "fpr_test, tpr_test, thresholds = roc_curve(y_test_encoded, y_test_proba)\n",
    "\n",
    "# Visualizar\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr_test, tpr_test, label=f'Logistic Regression - TEST (AUC={auc_test:.3f})', \n",
    "         linewidth=3, color='#e74c3c')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Modelo Aleatorio (AUC=0.5)', linewidth=1.5)\n",
    "\n",
    "# A√±adir l√≠nea de Validation para comparar\n",
    "plt.axhline(y=recall_val, color='#3498db', linestyle=':', linewidth=2, \n",
    "            label=f'Recall Validation ({recall_val:.3f})')\n",
    "\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)', fontsize=12)\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (Recall)', fontsize=12)\n",
    "plt.title('Curva ROC - Evaluaci√≥n en TEST', fontsize=14, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "# A√±adir anotaci√≥n\n",
    "plt.text(0.6, 0.3, f'Diferencia AUC:\\nVal: {auc_val:.4f}\\nTest: {auc_test:.4f}\\nDiff: {diff_auc:.2f}%',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "         fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/06_roc_curve_test.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Curva ROC guardada: reports/figures/06_roc_curve_test.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ee9f46",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 8. An√°lisis de Threshold √ìptimo\n",
    "\n",
    "### üéØ ¬øQu√© es el threshold?\n",
    "\n",
    "Por defecto, los modelos usan **threshold=0.5**:\n",
    "- Si probabilidad ‚â• 0.5 ‚Üí Predecir churn\n",
    "- Si probabilidad < 0.5 ‚Üí Predecir no churn\n",
    "\n",
    "Pero **podemos ajustar este threshold** seg√∫n el negocio:\n",
    "\n",
    "### üìä Trade-off Precision vs Recall:\n",
    "\n",
    "**Threshold BAJO (ej: 0.3)**:\n",
    "- ‚úÖ Mayor Recall: Detectamos M√ÅS churners reales\n",
    "- ‚ùå Menor Precision: M√°s falsos positivos (molestamos clientes que no se van a ir)\n",
    "- üí∞ Costo: Gastamos m√°s en campa√±as de retenci√≥n innecesarias\n",
    "\n",
    "**Threshold ALTO (ej: 0.7)**:\n",
    "- ‚úÖ Mayor Precision: Solo contactamos churners muy probables\n",
    "- ‚ùå Menor Recall: Perdemos churners con probabilidad media\n",
    "- üí∞ Costo: Perdemos m√°s clientes reales\n",
    "\n",
    "### üí° ¬øC√≥mo elegir?\n",
    "\n",
    "Depende del **costo de negocio**:\n",
    "- **Costo de retenci√≥n bajo** (ej: enviar email) ‚Üí Threshold bajo (detectar m√°s)\n",
    "- **Costo de perder cliente muy alto** ‚Üí Threshold bajo (no perder ninguno)\n",
    "- **Costo de retenci√≥n alto** (ej: descuento 50%) ‚Üí Threshold alto (solo muy seguros)\n",
    "\n",
    "Vamos a analizar diferentes thresholds para encontrar el √≥ptimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d6609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:38.979153Z",
     "start_time": "2026-01-11T03:53:38.940435Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calcular m√©tricas para diferentes thresholds\n",
    "thresholds_to_test = np.arange(0.1, 0.9, 0.05)\n",
    "results = []\n",
    "\n",
    "for threshold in thresholds_to_test:\n",
    "    y_pred_custom = (y_test_proba >= threshold).astype(int)\n",
    "    \n",
    "    prec = precision_score(y_test_encoded, y_pred_custom, zero_division=0)\n",
    "    rec = recall_score(y_test_encoded, y_pred_custom, zero_division=0)\n",
    "    f1 = f1_score(y_test_encoded, y_pred_custom, zero_division=0)\n",
    "    \n",
    "    results.append({\n",
    "        'Threshold': threshold,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "\n",
    "threshold_df = pd.DataFrame(results)\n",
    "\n",
    "# Encontrar threshold con mejor F1-Score\n",
    "best_threshold_idx = threshold_df['F1-Score'].idxmax()\n",
    "best_threshold = threshold_df.loc[best_threshold_idx, 'Threshold']\n",
    "best_f1 = threshold_df.loc[best_threshold_idx, 'F1-Score']\n",
    "\n",
    "print(\"üìä AN√ÅLISIS DE THRESHOLD √ìPTIMO\\n\")\n",
    "print(f\"üéØ Threshold DEFAULT (0.5):\")\n",
    "print(f\"   ‚Ä¢ Precision: {precision_test:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall:    {recall_test:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {f1_test:.4f}\")\n",
    "\n",
    "print(f\"\\nüèÜ Threshold √ìPTIMO ({best_threshold:.2f}):\")\n",
    "print(f\"   ‚Ä¢ Precision: {threshold_df.loc[best_threshold_idx, 'Precision']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall:    {threshold_df.loc[best_threshold_idx, 'Recall']:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {best_f1:.4f}\")\n",
    "\n",
    "# Mejora\n",
    "f1_improvement = (best_f1 - f1_test) / f1_test * 100\n",
    "print(f\"\\nüìà Mejora al ajustar threshold: {f1_improvement:+.2f}% en F1-Score\")\n",
    "\n",
    "# Mostrar top 5 thresholds\n",
    "print(f\"\\nüìã TOP 5 THRESHOLDS:\\n\")\n",
    "print(threshold_df.sort_values('F1-Score', ascending=False).head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f32cdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:39.263580Z",
     "start_time": "2026-01-11T03:53:38.992694Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizar Precision-Recall vs Threshold\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.plot(threshold_df['Threshold'], threshold_df['Precision'], \n",
    "        label='Precision', linewidth=2.5, marker='o', color='#3498db')\n",
    "ax.plot(threshold_df['Threshold'], threshold_df['Recall'], \n",
    "        label='Recall', linewidth=2.5, marker='s', color='#e74c3c')\n",
    "ax.plot(threshold_df['Threshold'], threshold_df['F1-Score'], \n",
    "        label='F1-Score', linewidth=2.5, marker='^', color='#2ecc71')\n",
    "\n",
    "# Marcar threshold √≥ptimo\n",
    "ax.axvline(x=best_threshold, color='black', linestyle='--', linewidth=2, \n",
    "           label=f'Threshold √ìptimo ({best_threshold:.2f})')\n",
    "ax.axvline(x=0.5, color='gray', linestyle=':', linewidth=1.5, \n",
    "           label='Threshold Default (0.5)')\n",
    "\n",
    "ax.set_xlabel('Threshold', fontsize=12)\n",
    "ax.set_ylabel('Valor de M√©trica', fontsize=12)\n",
    "ax.set_title('An√°lisis de Threshold: Precision vs Recall vs F1-Score', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best', fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_ylim([0, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/06_threshold_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì An√°lisis de threshold guardado: reports/figures/06_threshold_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f716507",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 9. Feature Importance: Coeficientes del Modelo\n",
    "\n",
    "### üéØ ¬øQu√© son los coeficientes?\n",
    "\n",
    "En **Logistic Regression**, cada feature tiene un **coeficiente** que indica su impacto en la predicci√≥n:\n",
    "\n",
    "- **Coeficiente POSITIVO (+)**: Aumenta probabilidad de churn\n",
    "  - Ej: `Contract_Month-to-Month` = +0.85 ‚Üí Contratos mensuales aumentan churn\n",
    "  \n",
    "- **Coeficiente NEGATIVO (-)**: Disminuye probabilidad de churn\n",
    "  - Ej: `Tenure` = -0.60 ‚Üí Mayor antig√ºedad reduce churn\n",
    "\n",
    "### üìä Interpretaci√≥n:\n",
    "\n",
    "**Magnitud del coeficiente** = Importancia relativa\n",
    "- |Coef| > 0.5 = Feature muy importante\n",
    "- |Coef| < 0.1 = Feature poco relevante\n",
    "\n",
    "### üí° ¬øPara qu√© sirve?\n",
    "\n",
    "**Insights de negocio**:\n",
    "- Si `InternetService_Fiber` tiene coef alto ‚Üí Clientes de fibra √≥ptica cancelan m√°s\n",
    "- Si `TotalCharges` tiene coef positivo ‚Üí Cuanto m√°s paguen, m√°s probabilidad de irse\n",
    "- Si `Contract_Two-Year` tiene coef negativo ‚Üí Contratos largos retienen mejor\n",
    "\n",
    "**Accionable**: Podemos dise√±ar estrategias de retenci√≥n basadas en los drivers principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8121c33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:39.281541Z",
     "start_time": "2026-01-11T03:53:39.270594Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extraer coeficientes del modelo\n",
    "feature_names = X_train.columns\n",
    "coefficients = model_champion.coef_[0]\n",
    "\n",
    "# Crear DataFrame\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': coefficients,\n",
    "    'Abs_Coefficient': np.abs(coefficients)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Top 15 features m√°s importantes\n",
    "top_15_coef = coef_df.head(15)\n",
    "\n",
    "print(\"üìä TOP 15 FEATURES M√ÅS IMPORTANTES (por coeficiente)\\n\")\n",
    "print(top_15_coef[['Feature', 'Coefficient']].to_string(index=False))\n",
    "\n",
    "# Interpretaci√≥n\n",
    "print(f\"\\nüí° INTERPRETACI√ìN:\\n\")\n",
    "print(f\"üî¥ AUMENTAN CHURN (coeficientes positivos):\")\n",
    "positive_top_3 = coef_df[coef_df['Coefficient'] > 0].head(3)\n",
    "for idx, row in positive_top_3.iterrows():\n",
    "    print(f\"   ‚Ä¢ {row['Feature']}: +{row['Coefficient']:.4f}\")\n",
    "\n",
    "print(f\"\\nüü¢ REDUCEN CHURN (coeficientes negativos):\")\n",
    "negative_top_3 = coef_df[coef_df['Coefficient'] < 0].head(3)\n",
    "for idx, row in negative_top_3.iterrows():\n",
    "    print(f\"   ‚Ä¢ {row['Feature']}: {row['Coefficient']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef0840",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:39.564636Z",
     "start_time": "2026-01-11T03:53:39.288401Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizar coeficientes\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "colors = ['red' if x > 0 else 'green' for x in top_15_coef['Coefficient']]\n",
    "\n",
    "plt.barh(range(len(top_15_coef)), top_15_coef['Coefficient'], color=colors, alpha=0.7)\n",
    "plt.yticks(range(len(top_15_coef)), top_15_coef['Feature'])\n",
    "plt.xlabel('Coeficiente (impacto en churn)', fontsize=12)\n",
    "plt.title('Top 15 Features por Coeficiente - Logistic Regression', fontsize=14, fontweight='bold')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Leyenda\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='red', alpha=0.7, label='Aumenta churn'),\n",
    "    Patch(facecolor='green', alpha=0.7, label='Reduce churn')\n",
    "]\n",
    "plt.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/06_feature_coefficients.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Coeficientes guardados: reports/figures/06_feature_coefficients.png\")\n",
    "\n",
    "# Guardar CSV\n",
    "coef_df.to_csv('../reports/06_feature_coefficients.csv', index=False)\n",
    "print(\"‚úì CSV guardado: reports/06_feature_coefficients.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd19d08c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 10. An√°lisis de Errores\n",
    "\n",
    "### üéØ ¬øQu√© analizamos?\n",
    "\n",
    "Vamos a inspeccionar los **Falsos Negativos** (FN) y **Falsos Positivos** (FP) para entender d√≥nde falla el modelo.\n",
    "\n",
    "### üìä Preguntas clave:\n",
    "\n",
    "**Falsos Negativos (predecimos no churn pero S√ç cancelan)**:\n",
    "- ¬øQu√© caracter√≠sticas tienen estos clientes?\n",
    "- ¬øHay patrones que el modelo no captura?\n",
    "- ¬øPodemos crear nuevas features para detectarlos?\n",
    "\n",
    "**Falsos Positivos (predecimos churn pero NO cancelan)**:\n",
    "- ¬øSon clientes satisfechos que parecen en riesgo?\n",
    "- ¬øQu√© los hace diferentes de los churners reales?\n",
    "\n",
    "### üí° Objetivo:\n",
    "Identificar **oportunidades de mejora** para el modelo y **insights de negocio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59175866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:39.577478Z",
     "start_time": "2026-01-11T03:53:39.569364Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identificar errores\n",
    "errors_df = pd.DataFrame({\n",
    "    'y_true': y_test_encoded,\n",
    "    'y_pred': y_test_pred,\n",
    "    'y_proba': y_test_proba\n",
    "})\n",
    "\n",
    "# Clasificar errores\n",
    "errors_df['Error_Type'] = 'Correct'\n",
    "errors_df.loc[(errors_df['y_true'] == 0) & (errors_df['y_pred'] == 1), 'Error_Type'] = 'False Positive'\n",
    "errors_df.loc[(errors_df['y_true'] == 1) & (errors_df['y_pred'] == 0), 'Error_Type'] = 'False Negative'\n",
    "\n",
    "# Contar\n",
    "error_counts = errors_df['Error_Type'].value_counts()\n",
    "\n",
    "print(\"üìä DISTRIBUCI√ìN DE ERRORES\\n\")\n",
    "print(f\"‚úÖ Predicciones Correctas: {error_counts.get('Correct', 0):,} ({error_counts.get('Correct', 0)/len(errors_df)*100:.1f}%)\")\n",
    "print(f\"‚ùå Falsos Positivos (FP):  {error_counts.get('False Positive', 0):,} ({error_counts.get('False Positive', 0)/len(errors_df)*100:.1f}%)\")\n",
    "print(f\"‚ùå Falsos Negativos (FN):  {error_counts.get('False Negative', 0):,} ({error_counts.get('False Negative', 0)/len(errors_df)*100:.1f}%)\")\n",
    "\n",
    "# An√°lisis de probabilidades de errores\n",
    "fp_probas = errors_df[errors_df['Error_Type'] == 'False Positive']['y_proba']\n",
    "fn_probas = errors_df[errors_df['Error_Type'] == 'False Negative']['y_proba']\n",
    "\n",
    "print(f\"\\nüìà AN√ÅLISIS DE PROBABILIDADES:\\n\")\n",
    "\n",
    "if len(fp_probas) > 0:\n",
    "    print(f\"Falsos Positivos:\")\n",
    "    print(f\"   ‚Ä¢ Probabilidad media: {fp_probas.mean():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Rango: [{fp_probas.min():.4f}, {fp_probas.max():.4f}]\")\n",
    "    print(f\"   ‚Ä¢ Interpretaci√≥n: El modelo tiene confianza media-alta en estos errores\\n\")\n",
    "\n",
    "if len(fn_probas) > 0:\n",
    "    print(f\"Falsos Negativos:\")\n",
    "    print(f\"   ‚Ä¢ Probabilidad media: {fn_probas.mean():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Rango: [{fn_probas.min():.4f}, {fn_probas.max():.4f}]\")\n",
    "    print(f\"   ‚Ä¢ Interpretaci√≥n: El modelo tiene BAJA confianza (cercano a 0.5)\")\n",
    "    print(f\"   ‚Ä¢ Acci√≥n: Son clientes 'borderline' dif√≠ciles de predecir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c3b540",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:39.919527Z",
     "start_time": "2026-01-11T03:53:39.581835Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualizar distribuci√≥n de probabilidades por tipo de error\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Falsos Positivos\n",
    "if len(fp_probas) > 0:\n",
    "    axes[0].hist(fp_probas, bins=20, color='orange', alpha=0.7, edgecolor='black')\n",
    "    axes[0].axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Threshold=0.5')\n",
    "    axes[0].set_title('Falsos Positivos: Distribuci√≥n de Probabilidades', fontweight='bold')\n",
    "    axes[0].set_xlabel('Probabilidad de Churn')\n",
    "    axes[0].set_ylabel('Frecuencia')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Falsos Negativos\n",
    "if len(fn_probas) > 0:\n",
    "    axes[1].hist(fn_probas, bins=20, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    axes[1].axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Threshold=0.5')\n",
    "    axes[1].set_title('Falsos Negativos: Distribuci√≥n de Probabilidades', fontweight='bold')\n",
    "    axes[1].set_xlabel('Probabilidad de Churn')\n",
    "    axes[1].set_ylabel('Frecuencia')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/06_error_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì An√°lisis de errores guardado: reports/figures/06_error_analysis.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec3b92a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 11. Reporte de Clasificaci√≥n Completo\n",
    "\n",
    "### üéØ ¬øQu√© es?\n",
    "\n",
    "Resumen ejecutivo con **todas las m√©tricas** desglosadas por clase (No Churn vs Churn).\n",
    "\n",
    "### üìä M√©tricas incluidas:\n",
    "\n",
    "**Por clase**:\n",
    "- **Precision**: De las predicciones de esa clase, cu√°ntas son correctas\n",
    "- **Recall**: De los reales de esa clase, cu√°ntos detectamos\n",
    "- **F1-Score**: Balance entre Precision y Recall\n",
    "- **Support**: Cantidad de muestras reales de esa clase\n",
    "\n",
    "**Globales**:\n",
    "- **Accuracy**: % de aciertos totales\n",
    "- **Macro avg**: Promedio simple de m√©tricas (trata ambas clases igual)\n",
    "- **Weighted avg**: Promedio ponderado por cantidad de muestras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae76af9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:39.937935Z",
     "start_time": "2026-01-11T03:53:39.926668Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generar reporte de clasificaci√≥n\n",
    "class_report = classification_report(\n",
    "    y_test_encoded, \n",
    "    y_test_pred,\n",
    "    target_names=['No Churn', 'Cancelacion'],\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìä REPORTE DE CLASIFICACI√ìN - TEST SET\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(classification_report(\n",
    "    y_test_encoded, \n",
    "    y_test_pred,\n",
    "    target_names=['No Churn', 'Cancelacion']\n",
    "))\n",
    "\n",
    "# Interpretaci√≥n\n",
    "print(\"\\nüí° INTERPRETACI√ìN:\\n\")\n",
    "print(f\"Clase 'No Churn' (Mayor√≠a):\")\n",
    "print(f\"   ‚Ä¢ Precision: {class_report['No Churn']['precision']:.3f} ‚Üí De los que predecimos como no churn, {class_report['No Churn']['precision']*100:.1f}% son correctos\")\n",
    "print(f\"   ‚Ä¢ Recall:    {class_report['No Churn']['recall']:.3f} ‚Üí Detectamos {class_report['No Churn']['recall']*100:.1f}% de los que realmente no cancelan\")\n",
    "\n",
    "print(f\"\\nClase 'Cancelacion' (Objetivo principal):\")\n",
    "print(f\"   ‚Ä¢ Precision: {class_report['Cancelacion']['precision']:.3f} ‚Üí De los que predecimos como churn, {class_report['Cancelacion']['precision']*100:.1f}% son correctos\")\n",
    "print(f\"   ‚Ä¢ Recall:    {class_report['Cancelacion']['recall']:.3f} ‚Üí Detectamos {class_report['Cancelacion']['recall']*100:.1f}% de los churners reales\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {class_report['Cancelacion']['f1-score']:.3f} ‚Üí Balance entre Precision y Recall\")\n",
    "\n",
    "print(f\"\\nOverall:\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {class_report['accuracy']:.3f} ‚Üí {class_report['accuracy']*100:.1f}% de predicciones correctas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6efd46",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 12. Guardar M√©tricas Finales\n",
    "\n",
    "### üéØ ¬øQu√© guardamos?\n",
    "\n",
    "Todas las m√©tricas de TEST en formato CSV y JSON para:\n",
    "- Documentaci√≥n del modelo\n",
    "- Comparaci√≥n con versiones futuras\n",
    "- Reportes ejecutivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d30c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:39.960866Z",
     "start_time": "2026-01-11T03:53:39.949609Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Crear reporte de m√©tricas\n",
    "test_metrics = {\n",
    "    'evaluation_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'model_name': 'Logistic Regression',\n",
    "    'model_path': 'models/champion/model_champion.pkl',\n",
    "    'test_set_size': len(X_test),\n",
    "    'test_churn_rate': float(y_test_encoded.sum() / len(y_test_encoded)),\n",
    "    'metrics': {\n",
    "        'auc': float(auc_test),\n",
    "        'accuracy': float(accuracy_test),\n",
    "        'precision': float(precision_test),\n",
    "        'recall': float(recall_test),\n",
    "        'f1_score': float(f1_test)\n",
    "    },\n",
    "    'confusion_matrix': {\n",
    "        'true_negatives': int(tn),\n",
    "        'false_positives': int(fp),\n",
    "        'false_negatives': int(fn),\n",
    "        'true_positives': int(tp)\n",
    "    },\n",
    "    'validation_comparison': {\n",
    "        'auc_val': float(auc_val),\n",
    "        'auc_test': float(auc_test),\n",
    "        'auc_diff_pct': float(diff_auc),\n",
    "        'f1_val': float(f1_val),\n",
    "        'f1_test': float(f1_test),\n",
    "        'f1_diff_pct': float(diff_f1)\n",
    "    },\n",
    "    'threshold_analysis': {\n",
    "        'default_threshold': 0.5,\n",
    "        'optimal_threshold': float(best_threshold),\n",
    "        'optimal_f1': float(best_f1),\n",
    "        'f1_improvement_pct': float(f1_improvement)\n",
    "    },\n",
    "    'production_ready': diff_auc < 5 and diff_f1 < 5\n",
    "}\n",
    "\n",
    "# Guardar JSON\n",
    "with open('../reports/06_test_metrics.json', 'w') as f:\n",
    "    json.dump(test_metrics, f, indent=2)\n",
    "\n",
    "print(\"‚úì M√©tricas guardadas: reports/06_test_metrics.json\")\n",
    "\n",
    "# Guardar CSV resumido\n",
    "metrics_summary = pd.DataFrame([\n",
    "    {'M√©trica': 'AUC', 'Validation': auc_val, 'Test': auc_test, 'Diferencia %': diff_auc},\n",
    "    {'M√©trica': 'Accuracy', 'Validation': 'N/A', 'Test': accuracy_test, 'Diferencia %': 'N/A'},\n",
    "    {'M√©trica': 'Precision', 'Validation': precision_val, 'Test': precision_test, 'Diferencia %': diff_precision},\n",
    "    {'M√©trica': 'Recall', 'Validation': recall_val, 'Test': recall_test, 'Diferencia %': diff_recall},\n",
    "    {'M√©trica': 'F1-Score', 'Validation': f1_val, 'Test': f1_test, 'Diferencia %': diff_f1}\n",
    "])\n",
    "\n",
    "metrics_summary.to_csv('../reports/06_test_metrics.csv', index=False)\n",
    "print(\"‚úì CSV guardado: reports/06_test_metrics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54c9d48",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 13. Resumen Final y Conclusiones\n",
    "\n",
    "### ‚úÖ DS-506 COMPLETADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2fe332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T03:53:39.975824Z",
     "start_time": "2026-01-11T03:53:39.969884Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ DS-506 COMPLETADO - EVALUACI√ìN EXHAUSTIVA EN TEST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüéØ MODELO EVALUADO: Logistic Regression (Campe√≥n)\")\n",
    "\n",
    "print(\"\\nüìä M√âTRICAS FINALES EN TEST:\")\n",
    "print(f\"   ‚Ä¢ AUC:       {auc_test:.4f}\")\n",
    "print(f\"   ‚Ä¢ Accuracy:  {accuracy_test:.4f}\")\n",
    "print(f\"   ‚Ä¢ Precision: {precision_test:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall:    {recall_test:.4f}\")\n",
    "print(f\"   ‚Ä¢ F1-Score:  {f1_test:.4f}\")\n",
    "\n",
    "print(\"\\nüìà COMPARACI√ìN CON VALIDATION:\")\n",
    "print(f\"   ‚Ä¢ Diferencia AUC:      {diff_auc:+.2f}%\")\n",
    "print(f\"   ‚Ä¢ Diferencia F1-Score: {diff_f1:+.2f}%\")\n",
    "\n",
    "print(\"\\nüéØ THRESHOLD √ìPTIMO:\")\n",
    "print(f\"   ‚Ä¢ Default (0.5): F1={f1_test:.4f}\")\n",
    "print(f\"   ‚Ä¢ √ìptimo ({best_threshold:.2f}): F1={best_f1:.4f} ({f1_improvement:+.2f}%)\")\n",
    "\n",
    "print(\"\\n‚ùå AN√ÅLISIS DE ERRORES:\")\n",
    "print(f\"   ‚Ä¢ Falsos Positivos: {fp:,} ({fp/len(y_test_encoded)*100:.1f}%) - Malgasto de recursos de retenci√≥n\")\n",
    "print(f\"   ‚Ä¢ Falsos Negativos: {fn:,} ({fn/len(y_test_encoded)*100:.1f}%) - Clientes perdidos\")\n",
    "\n",
    "print(\"\\nüèÜ DECISI√ìN FINAL:\")\n",
    "if test_metrics['production_ready']:\n",
    "    print(\"   ‚úÖ MODELO APROBADO PARA PRODUCCI√ìN\")\n",
    "    print(\"   ‚Ä¢ Generaliza excelente (diferencia <5% con Validation)\")\n",
    "    print(\"   ‚Ä¢ AUC > 0.90 (Excelente capacidad discriminativa)\")\n",
    "    print(\"   ‚Ä¢ Listo para integrar con backend Java (FastAPI)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è MODELO REQUIERE AJUSTES\")\n",
    "    print(\"   ‚Ä¢ Diferencia significativa con Validation\")\n",
    "    print(\"   ‚Ä¢ Considerar reentrenar con m√°s regularizaci√≥n\")\n",
    "\n",
    "print(\"\\nüìÅ ARCHIVOS GENERADOS:\")\n",
    "print(\"\\n   Reportes:\")\n",
    "print(\"   1. reports/06_test_metrics.json\")\n",
    "print(\"   2. reports/06_test_metrics.csv\")\n",
    "print(\"   3. reports/06_confusion_matrix.csv\")\n",
    "print(\"   4. reports/06_feature_coefficients.csv\")\n",
    "\n",
    "print(\"\\n   Visualizaciones:\")\n",
    "print(\"   5. reports/figures/06_confusion_matrix.png\")\n",
    "print(\"   6. reports/figures/06_roc_curve_test.png\")\n",
    "print(\"   7. reports/figures/06_threshold_analysis.png\")\n",
    "print(\"   8. reports/figures/06_feature_coefficients.png\")\n",
    "print(\"   9. reports/figures/06_error_analysis.png\")\n",
    "\n",
    "print(\"\\nüé´ PR√ìXIMO TICKET:\")\n",
    "print(\"   DS-507: Crear Pipeline de Producci√≥n Completo\")\n",
    "print(\"   ‚Ä¢ Integraci√≥n con FastAPI\")\n",
    "print(\"   ‚Ä¢ Endpoint /predict funcional\")\n",
    "print(\"   ‚Ä¢ Testing con datos reales\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Modelo Logistic Regression VALIDADO y LISTO PARA PRODUCCI√ìN\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.809441,
   "end_time": "2026-01-16T15:11:41.287492",
   "environment_variables": {},
   "exception": true,
   "input_path": "notebooks/06_champion_evaluation.ipynb",
   "output_path": "notebooks/06_champion_evaluation.ipynb",
   "parameters": {},
   "start_time": "2026-01-16T15:11:38.478051",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}